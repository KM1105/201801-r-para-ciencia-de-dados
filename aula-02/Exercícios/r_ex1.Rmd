---
title: "Resposta exercício 1 (tarde)"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Exercício

1) Gere uma amostra aleatória de tamanho 10 de pares (X,Y) com a seguinte relação:

$$
Y = 2 + 3X + X^2 + \epsilon, \quad X \sim U(0, 1), \quad \epsilon \sim N(0, 0.3)
$$




```{r}
# Como vamos gerar números aleatórios, precisamos setar uma semente para que nossos resultados possam ser reprodutíveis.

set.seed(31012018)

# Gerar uma amostra de tamanho 10 da distribuição uniforme. Para isso, utilize a função runif().

x <- runif(10)

# Gerar uma amostra de tamanho 10 da distribuição normal com média 0 e variância 0.3. Para isso, utilize a função rnorm().

e <- rnorm(10, 0, 0.3)

# Crie a variável Y conforme a relação apresentada acima.

y <- 2 + 3*x + x^2 + e


```

2) Crie o data.frame "dados" com as variáveis y e x.

```{r}
# Utilize a funçao data.frame() ou tibble(). Nomeie as colunas com "x" e "y".

dados <- tibble(x = x,
                y = y)
```

3) Crie um gráfico de dispersão de Y por X.

```{r}
ggplot(dados) +
  geom_point(aes(x = x, y = y))
```

4) Ajuste modelos de regressão polinomiais de grau 1 a 9 aos dados. Um modelo polinomial de grau p é dado por:

$$
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2^2 + \cdots \beta_p X_p^p + \epsilon
$$
```{r}
# Dica: utilize a função poly(x, p) para criar modelos polinomiais.

modelo1 <-  lm(y ~ x, data = dados)
modelo2 <- lm(y ~ poly(x, 2), data = dados)
modelo3 <- lm(y ~ poly(x, 3), data = dados)
modelo4 <- lm(y ~ poly(x, 4), data = dados)
modelo5 <- lm(y ~ poly(x, 5), data = dados)
modelo6 <- lm(y ~ poly(x, 6), data = dados)
modelo7 <- lm(y ~ poly(x, 7), data = dados)
modelo8 <- lm(y ~ poly(x, 8), data = dados)
modelo9 <- lm(y ~ poly(x, 9), data = dados)
```

5) Considere o erro de ajuste dado por

$$
EQM = \frac{1}{n}\sum_{i=1}^n(y - \hat{y})^2.
$$



Qual modelo você acredita ter o menor EQM? Rode o código abaixo e verifique.

```{r}
erro_modelo1 <- mean((dados$y - predict(modelo, newdata = dados))^2)
erro_modelo2 <- mean((dados$y - predict(modelo2, newdata = dados))^2)
erro_modelo3 <- mean((dados$y - predict(modelo3, newdata = dados))^2)
erro_modelo4 <- mean((dados$y - predict(modelo4, newdata = dados))^2)
erro_modelo5 <- mean((dados$y - predict(modelo5, newdata = dados))^2)
erro_modelo6 <- mean((dados$y - predict(modelo6, newdata = dados))^2)
erro_modelo7 <- mean((dados$y - predict(modelo7, newdata = dados))^2)
erro_modelo8 <- mean((dados$y - predict(modelo8, newdata = dados))^2)
erro_modelo9 <- mean((dados$y - predict(modelo9, newdata = dados))^2)

erro_ajuste <- c(erro_modelo1 = erro_modelo1,
erro_modelo2 = erro_modelo2,
erro_modelo3 = erro_modelo3,
erro_modelo4 = erro_modelo4,
erro_modelo5 = erro_modelo5,
erro_modelo6 = erro_modelo6,
erro_modelo7 = erro_modelo7,
erro_modelo8 = erro_modelo8,
erro_modelo9 = erro_modelo9) %>% round(3)

erro_ajuste
```
